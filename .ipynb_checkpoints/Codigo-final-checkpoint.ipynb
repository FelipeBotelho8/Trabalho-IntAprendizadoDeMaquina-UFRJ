{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar bibliotecas\n",
    "\n",
    "#Para manipulacoes de dados\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "#Para manipular datas\n",
    "from datetime import datetime\n",
    "\n",
    "#Para limpar uso de memoria\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para o pre-processamento dos dados\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Para a contrucao do modelo\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando os dados para treino\n",
    "\n",
    "\n",
    "building = pd.read_csv(\"../input/ashrae-energy-prediction/building_metadata.csv\")\n",
    "train = pd.read_csv(\"../input/ashrae-energy-prediction/train.csv\")\n",
    "weather_train = pd.read_csv(\"../input/ashrae-energy-prediction/weather_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para reduzir o uso de memoria do dataframe\n",
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_memory_usage(building)\n",
    "reduce_memory_usage(weather_train)\n",
    "reduce_memory_usage(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando a coluna floor_count do df building\n",
    "building.drop(columns=[\"floor_count\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juntando os dataframes\n",
    "one_train = train.merge(building, on=\"building_id\", how=\"left\")\n",
    "one_train = one_train.merge(weather_train,\n",
    "                            on=[\"site_id\", \"timestamp\"],\n",
    "                            how=\"left\")\n",
    "\n",
    "#Converter a coluna timestamp para o tipo data\n",
    "one_train[\"timestamp\"] = pd.to_datetime(one_train[\"timestamp\"],\n",
    "                                        format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando os dfs que nao vao mais ser usados\n",
    "del weather_train\n",
    "del building\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcao para converter os angulos de direcao do vento em categorias de direcao\n",
    "def angle_2_direction(angle):\n",
    "    if ((angle <= 45) or (angle > 315)): #direcao leste\n",
    "        return 0\n",
    "    elif ((angle <= 135) and (angle > 45)): #direcao norte\n",
    "        return 1\n",
    "    elif ((angle <= 225) and (angle > 135)): #direcao oeste\n",
    "        return 2\n",
    "    elif ((angle <= 315) and (angle > 225)): #direcao sul\n",
    "        return 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo wind_direction \n",
    "one_train['wind_compass_direction'] = one_train.wind_direction.apply(angle_2_direction)\n",
    "one_train.drop(columns=[\"wind_direction\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar as categorias de meter em colunas com LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "meter_coded = lb.fit_transform(one_train['meter'])\n",
    "\n",
    "meter_coded_df = pd.DataFrame({'meter_0': meter_coded[:,0],\n",
    "                               'meter_1': meter_coded[:,1],\n",
    "                               'meter_2': meter_coded[:,2],\n",
    "                               'meter_3': meter_coded[:,3]})\n",
    "\n",
    "one_train['meter_0'] = meter_coded_df['meter_0']\n",
    "one_train['meter_1'] = meter_coded_df['meter_1']\n",
    "one_train['meter_2'] = meter_coded_df['meter_2']\n",
    "one_train['meter_3'] = meter_coded_df['meter_3']\n",
    "\n",
    "one_train.drop(columns=['meter'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar as categorias de primary_use em numerica\n",
    "le = LabelEncoder()\n",
    "primary_use_coded = le.fit_transform(one_train['primary_use'])\n",
    "\n",
    "one_train['primary_use'] = primary_use_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar building age em idade atual da construcao\n",
    "year = datetime.now().year\n",
    "one_train['building_age'] = year - one_train['year_built']\n",
    "one_train.drop(columns=['year_built'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionar colunas para mes, dia da semana e hora\n",
    "one_train['month'] = one_train['timestamp'].dt.month.astype(np.int8)\n",
    "one_train['weekday'] = one_train['timestamp'].dt.dayofweek.astype(np.int8)\n",
    "one_train['hour'] = one_train['timestamp'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando os valores com alvo igual a zero\n",
    "one_train = one_train[one_train['meter_reading'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando meter_reading em log_meter_reading\n",
    "one_train['log_meter_reading'] = np.log1p(one_train.meter_reading)\n",
    "one_train.drop(columns=['meter_reading'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisar a matriz de correlacoes\n",
    "corr_df = pd.DataFrame(one_train.corr())\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df['log_meter_reading'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando a coluna site_id  ja que eh muito correlacionada com building_id\n",
    "one_train.drop(columns=['site_id'], inplace=True)\n",
    "\n",
    "#Retirando timestamp\n",
    "one_train.drop(columns=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando a coluna alvo\n",
    "X = one_train.drop('log_meter_reading', axis=1)\n",
    "y = one_train['log_meter_reading'].copy()\n",
    "\n",
    "del one_train\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcao para substituir os valores faltantes(nan) em cada coluna pela mediana\n",
    "def My_Imputer(df_train):\n",
    "    for col in df_train.columns:\n",
    "        col_median = df_train[col].median()\n",
    "        df_train[col].replace(np.nan, col_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substituir os valores faltantes\n",
    "My_Imputer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X:\n",
    "    print(\"Num de NaN: \", X[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando tipo de algumas features para liberar espaco\n",
    "X['primary_use'] = X['primary_use'].astype('int8')\n",
    "X['wind_compass_direction'] = X['wind_compass_direction'].astype('int8')\n",
    "X['meter_0'] = X['meter_0'].astype('int8')\n",
    "X['meter_1'] = X['meter_1'].astype('int8')\n",
    "X['meter_2'] = X['meter_2'].astype('int8')\n",
    "X['meter_3'] = X['meter_3'].astype('int8')\n",
    "X['building_age'] = X['building_age'].astype('int8')\n",
    "X['cloud_coverage'] = X['cloud_coverage'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando Regressao Linear\n",
    "lr = LinearRegression()\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=False, random_state=42)\n",
    "count = 1\n",
    "for train_index, val_index in kf.split(X):\n",
    "    print(\"SPLIT: \", count)\n",
    "    count+=1\n",
    "    \n",
    "    X_train_kf =  X.iloc[train_index]\n",
    "    y_train_kf = y.iloc[train_index]\n",
    "    X_val_kf = X.iloc[val_index]\n",
    "    y_val_kf = y.iloc[val_index]\n",
    "    \n",
    "    lr = lr.fit(X_train_kf, y_train_kf)   \n",
    "                             \n",
    "    y_pred_in = lr.predict(X_train_kf)\n",
    "    y_pred_out = lr.predict(X_val_kf)\n",
    "    \n",
    "    rmse_in = sqrt(mean_squared_error(y_train_kf, y_pred_in))\n",
    "    rmse_out = sqrt(mean_squared_error(y_val_kf, y_pred_out))\n",
    "    \n",
    "    print(\"Erro dentro: \", rmse_in)\n",
    "    print(\"Erro fora: \", rmse_out)    \n",
    "    print(\"\")\n",
    "\n",
    "    del X_train_kf\n",
    "    del y_train_kf\n",
    "    del X_val_kf\n",
    "    del y_val_kf\n",
    "    del y_pred_in\n",
    "    del y_pred_out\n",
    "    gc.collect()\n",
    "                \n",
    "y_pred = lr.predict(X)\n",
    "rmse = sqrt(mean_squared_error(y, y_pred))\n",
    "print(\"Erro: \", rmse)\n",
    "\n",
    "del y_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando o LGBMRegressor\n",
    "cat_features = ['building_id', 'primary_use', 'wind_compass_direction',\n",
    "                'meter_0', 'meter_1', 'meter_2', 'meter_3']\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=False, random_state=42)\n",
    "lgbm_reg = lgb.LGBMRegressor(random_state=42,\n",
    "                             num_leaves=40,\n",
    "                             learning_rate=0.05,\n",
    "                             n_estimators=500,\n",
    "                             reg_alpha=1,\n",
    "                             reg_lambda=1)\n",
    "\n",
    "count = 1\n",
    "for train_index, val_index in kf.split(X):\n",
    "    print(\"SPLIT: \", count)\n",
    "    count+=1\n",
    "    \n",
    "    X_train_kf =  X.iloc[train_index]\n",
    "    y_train_kf = y.iloc[train_index]\n",
    "    X_val_kf = X.iloc[val_index]\n",
    "    y_val_kf = y.iloc[val_index]\n",
    "    \n",
    "    lgbm_reg = lgbm_reg.fit(X_train_kf, y_train_kf,\n",
    "                            categorical_feature=cat_features\n",
    "                           )\n",
    "    \n",
    "                             \n",
    "    y_pred_in = lgbm_reg.predict(X_train_kf)\n",
    "    y_pred_out = lgbm_reg.predict(X_val_kf)\n",
    "    \n",
    "    rmse_in = sqrt(mean_squared_error(y_train_kf, y_pred_in))\n",
    "    rmse_out = sqrt(mean_squared_error(y_val_kf, y_pred_out))\n",
    "    \n",
    "    print(\"Erro dentro: \", rmse_in)\n",
    "    print(\"Erro out: \", rmse_out)    \n",
    "    print(\"\")\n",
    "    \n",
    "    del X_train_kf\n",
    "    del y_train_kf\n",
    "    del X_val_kf\n",
    "    del y_val_kf\n",
    "    del y_pred_in\n",
    "    del y_pred_out\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimar os valores\n",
    "y_pred = lgbm_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular o erro\n",
    "rmse = sqrt(mean_squared_error(y, y_pred))\n",
    "print(\"RMSE: \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirar as variaveis que nao serao mais usadas\n",
    "del X\n",
    "del y\n",
    "del y_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando os dados para teste\n",
    "gc.collect()\n",
    "weather_test = pd.read_csv(\"../input/ashrae-energy-prediction/weather_test.csv\")\n",
    "test = pd.read_csv(\"../input/ashrae-energy-prediction/test.csv\")\n",
    "building = pd.read_csv(\"../input/ashrae-energy-prediction/building_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_memory_usage(weather_test)\n",
    "reduce_memory_usage(test)\n",
    "reduce_memory_usage(building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando a coluna floor_count do df building\n",
    "building.drop(columns=[\"floor_count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juntando os dataframes\n",
    "one_test = test.merge(building, on=\"building_id\", how=\"left\")\n",
    "one_test = one_test.merge(weather_test,\n",
    "                            on=[\"site_id\", \"timestamp\"],\n",
    "                            how=\"left\")\n",
    "\n",
    "#Converter a coluna timestamp para o tipo data\n",
    "one_test[\"timestamp\"] = pd.to_datetime(one_test[\"timestamp\"],\n",
    "                                        format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando os dfs que nao vao mais ser usados\n",
    "del weather_test\n",
    "del building\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo wind_direction \n",
    "one_test['wind_compass_direction'] = one_test.wind_direction.apply(angle_2_direction)\n",
    "one_test.drop(columns=[\"wind_direction\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar as categorias de meter em colunas com LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "meter_coded = lb.fit_transform(one_test['meter'])\n",
    "\n",
    "meter_coded_df = pd.DataFrame({'meter_0': meter_coded[:,0],\n",
    "                               'meter_1': meter_coded[:,1],\n",
    "                               'meter_2': meter_coded[:,2],\n",
    "                               'meter_3': meter_coded[:,3]})\n",
    "\n",
    "one_test['meter_0'] = meter_coded_df['meter_0']\n",
    "one_test['meter_1'] = meter_coded_df['meter_1']\n",
    "one_test['meter_2'] = meter_coded_df['meter_2']\n",
    "one_test['meter_3'] = meter_coded_df['meter_3']\n",
    "\n",
    "one_test.drop(columns=['meter'], inplace=True)\n",
    "del lb, meter_coded, meter_coded_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar as categorias de primary_use em numerica\n",
    "le = LabelEncoder()\n",
    "primary_use_coded = le.fit_transform(one_test['primary_use'])\n",
    "\n",
    "one_test['primary_use'] = primary_use_coded\n",
    "\n",
    "del le, primary_use_coded\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar building age em idade atual da construcao\n",
    "year = datetime.now().year\n",
    "one_test['building_age'] = year - one_test['year_built']\n",
    "one_test.drop(columns=['year_built'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionar colunas para mes, dia da semana, hora e ano\n",
    "one_test['month'] = one_test['timestamp'].dt.month.astype(np.int8)\n",
    "one_test['weekday'] = one_test['timestamp'].dt.dayofweek.astype(np.int8)\n",
    "one_test['hour'] = one_test['timestamp'].dt.hour\n",
    "one_test[\"year\"] = one_test[\"timestamp\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando a coluna site_id  ja que eh muito correlacionada com building_id\n",
    "one_test.drop(columns=['site_id'], inplace=True)\n",
    "\n",
    "#Retirando timestamp\n",
    "one_test.drop(columns=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando one_test em dois dfs pelos anos de 2017 e 2018\n",
    "test_2017 = one_test[one_test['year'] == 2017]\n",
    "test_2018 = one_test[one_test['year'] == 2018]\n",
    "\n",
    "del one_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando coluna de ano \n",
    "test_2017.drop(columns=['year'], inplace=True)\n",
    "test_2018.drop(columns=['year'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando a coluna row_id\n",
    "test_2017.drop(columns=['row_id'], inplace=True)\n",
    "test_2018.drop(columns=['row_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substituir os valores faltantes pela mediana\n",
    "My_Imputer(test_2017)\n",
    "My_Imputer(test_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_2018:\n",
    "    print(\"Num de NaN: \", test_2018[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando tipo de algumas features para liberar espaco\n",
    "test_2017['primary_use'] = test_2017['primary_use'].astype('int8')\n",
    "test_2017['wind_compass_direction'] = test_2017['wind_compass_direction'].astype('int8')\n",
    "test_2017['meter_0'] = test_2017['meter_0'].astype('int8')\n",
    "test_2017['meter_1'] = test_2017['meter_1'].astype('int8')\n",
    "test_2017['meter_2'] = test_2017['meter_2'].astype('int8')\n",
    "test_2017['meter_3'] = test_2017['meter_3'].astype('int8')\n",
    "test_2017['building_age'] = test_2017['building_age'].astype('int8')\n",
    "test_2017['cloud_coverage'] = test_2017['cloud_coverage'].astype('int8')\n",
    "\n",
    "test_2018['primary_use'] = test_2018['primary_use'].astype('int8')\n",
    "test_2018['wind_compass_direction'] = test_2018['wind_compass_direction'].astype('int8')\n",
    "test_2018['meter_0'] = test_2018['meter_0'].astype('int8')\n",
    "test_2018['meter_1'] = test_2018['meter_1'].astype('int8')\n",
    "test_2018['meter_2'] = test_2018['meter_2'].astype('int8')\n",
    "test_2018['meter_3'] = test_2018['meter_3'].astype('int8')\n",
    "test_2018['building_age'] = test_2018['building_age'].astype('int8')\n",
    "test_2018['cloud_coverage'] = test_2018['cloud_coverage'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_memory_usage(test_2017)\n",
    "reduce_memory_usage(test_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar tamanho dos dfs\n",
    "print(test_2017.shape)\n",
    "print(test_2018.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimar os valores de 2017\n",
    "preds_2017 = lgbm_reg.predict(test_2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desfazendo a conversao log+1 para meter_reading\n",
    "preds_2017 = np.expm1(preds_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimar os valores de 2018\n",
    "preds_2018 = lgbm_reg.predict(test_2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desfazendo a conversao log+1 para meter_reading\n",
    "preds_2018 = np.expm1(preds_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pegar as lihas para submissao\n",
    "sample_sub = pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/sample_submission.csv\")\n",
    "row_ids = sample_sub.row_id\n",
    "\n",
    "del sample_sub\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organizando as ids das linhas para submissao\n",
    "ids_2017 = row_ids[:preds_2017.shape[0]]\n",
    "ids_2018 = row_ids[preds_2018.shape[0]:]\n",
    "\n",
    "#Organizando o df para submissao\n",
    "sub_2017 = pd.DataFrame({'row_id': ids_2017,\n",
    "                         'meter_reading': np.clip(preds_2017,\n",
    "                                                  0, a_max=None)})\n",
    "sub_2018 = pd.DataFrame({'row_id': ids_2018,\n",
    "                         'meter_reading': np.clip(preds_2018,\n",
    "                                                  0, a_max=None)})\n",
    "submission = pd.concat([sub_2017, sub_2018])\n",
    "\n",
    "del sub_2017, sub_2018\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
